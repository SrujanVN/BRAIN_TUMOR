# -*- coding: utf-8 -*-
"""BRAIN_TUMOR

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Yld-OVYK1KktxuDo2HJSNOx54ldguhss
"""

from google.colab import drive
drive.mount('/content/drive')

from tensorflow.keras.preprocessing.image import ImageDataGenerator

# Define paths, include the path to the google drive
train_dir = '/content/drive/MyDrive/BRAIN_TUMOR/Training' # Updated train_dir
test_dir = '/content/drive/MyDrive/BRAIN_TUMOR/Testing'  # Updated test_dir

# Define image size
IMG_SIZE = 224

# ImageDataGenerators
train_datagen = ImageDataGenerator(
    rescale=1./255,
    rotation_range=30,
    zoom_range=0.2,
    width_shift_range=0.2,
    height_shift_range=0.2,
    horizontal_flip=True
)

test_datagen = ImageDataGenerator(rescale=1./255)

# Create generators
train_generator = train_datagen.flow_from_directory(
    train_dir,
    target_size=(IMG_SIZE, IMG_SIZE),
    batch_size=32,
    class_mode='binary'  # Tumor vs NoTumor = binary classification
)

test_generator = test_datagen.flow_from_directory(
    test_dir,
    target_size=(IMG_SIZE, IMG_SIZE),
    batch_size=32,
    class_mode='binary'
)

import os

for folder in ['Training', 'Testing']:
    path = f'/content/drive/MyDrive/BRAIN_TUMOR/{folder}'
    for subfolder in os.listdir(path):
        subfolder_path = os.path.join(path, subfolder)
        print(f"üìÇ Folder: {subfolder}")
        if os.path.isdir(subfolder_path):
            for file in os.listdir(subfolder_path)[:5]:  # only showing first 5 files
                print("   -", file)

import os

# Let's go deeper inside each folder
for folder in ['Training', 'Testing']:
    path = f'/content/drive/MyDrive/BRAIN_TUMOR/{folder}'
    for subfolder in os.listdir(path):
        subfolder_path = os.path.join(path, subfolder)
        if os.path.isdir(subfolder_path):
            for root, dirs, files in os.walk(subfolder_path):
                print(f"üìÇ Inside {root}: Found {len(files)} files.")
                for file in files[:5]:  # only first 5 files
                    print("   -", file)

import os

base_path = "/content/drive/MyDrive/BRAIN_TUMOR/"

# Check contents in each folder
for folder in ['Training', 'Testing']:
    for category in ['notumor', 'meningioma', 'pituitary', 'glioma']:
        folder_path = os.path.join(base_path, folder, category)
        print(f"Files in {folder_path}: {os.listdir(folder_path)}")

from PIL import Image

img_path = "/content/drive/MyDrive/BRAIN_TUMOR/Testing/glioma/Te-glTr_0000.jpg"
img = Image.open(img_path)
img.show()

from tensorflow.keras.preprocessing.image import ImageDataGenerator

# Data preprocessing
train_datagen = ImageDataGenerator(
    rescale=1./255,  # Normalize pixel values to [0, 1]
    rotation_range=20,
    width_shift_range=0.2,
    height_shift_range=0.2,
    shear_range=0.2,
    zoom_range=0.2,
    horizontal_flip=True,
    fill_mode='nearest'
)

test_datagen = ImageDataGenerator(rescale=1./255)

# Load data from directories
train_generator = train_datagen.flow_from_directory(
    '/content/drive/MyDrive/BRAIN_TUMOR/Training/',
    target_size=(224, 224),
    batch_size=32,
    class_mode='categorical'
)

validation_generator = test_datagen.flow_from_directory(
    '/content/drive/MyDrive/BRAIN_TUMOR/Testing/',
    target_size=(224, 224),
    batch_size=32,
    class_mode='categorical'
)

# Checking classes
print(train_generator.class_indices)

# Checking shapes
images, labels = next(train_generator)
print(images.shape)  # Should be (batch_size, 224, 224, 3)
print(labels.shape)  # Should be (batch_size,)

train_path = '/content/drive/MyDrive/BRAIN_TUMOR/Training/'
test_path = '/content/drive/MyDrive/BRAIN_TUMOR/Testing/'

from tensorflow.keras.preprocessing.image import ImageDataGenerator

# Define train and test ImageDataGenerators
train_datagen = ImageDataGenerator(
    rescale=1./255,
    rotation_range=30,
    zoom_range=0.2,
    width_shift_range=0.2,
    height_shift_range=0.2,
    horizontal_flip=True
)

test_datagen = ImageDataGenerator(rescale=1./255)

train_generator = train_datagen.flow_from_directory(
    train_path,
    target_size=(224, 224),
    batch_size=32,
    class_mode='categorical'
)

test_generator = test_datagen.flow_from_directory(
    test_path,
    target_size=(224, 224),
    batch_size=32,
    class_mode='categorical'
)

import numpy as np
from PIL import Image

image_sizes = []
channels = []

# Let's sample 100 random images
for class_name in class_names:
    class_folder = os.path.join(train_path, class_name)
    images_in_class = os.listdir(class_folder)
    random_images = random.sample(images_in_class, min(25, len(images_in_class)))  # up to 25 per class

    for image_name in random_images:
        image_path = os.path.join(class_folder, image_name)
        img = Image.open(image_path)

        image_sizes.append(img.size)  # (width, height)
        channels.append(len(img.getbands()))  # channels (1=grayscale, 3=RGB)

# Convert to array
widths, heights = zip(*image_sizes)

print(f"Average Width: {np.mean(widths):.2f}")
print(f"Average Height: {np.mean(heights):.2f}")
print(f"Minimum Width: {np.min(widths)}")
print(f"Minimum Height: {np.min(heights)}")
print(f"Maximum Width: {np.max(widths)}")
print(f"Maximum Height: {np.max(heights)}")
print(f"\nImage Channels (1=Grayscale, 3=RGB): {set(channels)}")

from tensorflow.keras.preprocessing.image import ImageDataGenerator

# Set image size
IMG_SIZE = (224, 224)

# Data augmentation and rescaling
train_datagen = ImageDataGenerator(
    rescale=1./255,
    rotation_range=20,
    width_shift_range=0.2,
    height_shift_range=0.2,
    shear_range=0.2,
    zoom_range=0.2,
    horizontal_flip=True,
    fill_mode='nearest'
)

test_datagen = ImageDataGenerator(
    rescale=1./255
)

# Loading training images
train_generator = train_datagen.flow_from_directory(
    '/content/drive/MyDrive/BRAIN_TUMOR/Training',
    target_size=IMG_SIZE,
    batch_size=32,
    class_mode='categorical',
    color_mode='rgb'  # Force everything into RGB
)

# Loading testing images
test_generator = test_datagen.flow_from_directory(
    '/content/drive/MyDrive/BRAIN_TUMOR/Testing',
    target_size=IMG_SIZE,
    batch_size=32,
    class_mode='categorical',
    color_mode='rgb'  # Force everything into RGB
)

import seaborn as sns
import pandas as pd

# Counting images per class
train_counts = {class_name: len(os.listdir(os.path.join(train_path, class_name)))
                for class_name in class_names}

train_df = pd.DataFrame(list(train_counts.items()), columns=['Class', 'Number of Images'])

# Plotting
plt.figure(figsize=(10,6))
sns.barplot(x='Class', y='Number of Images', data=train_df, palette='viridis')
plt.title('Class Distribution in Training Data', fontsize=16)
plt.xlabel('Tumor Class')
plt.ylabel('Number of Images')
plt.show()

import matplotlib.pyplot as plt
import matplotlib.image as mpimg
import random
import os

# Updated path
train_path = '/content/drive/MyDrive/BRAIN_TUMOR/Training'
class_names = os.listdir(train_path)

# Plotting
plt.figure(figsize=(16, 10))

for idx, class_name in enumerate(class_names):
    class_folder = os.path.join(train_path, class_name)
    image_name = random.choice(os.listdir(class_folder))
    image_path = os.path.join(class_folder, image_name)

    img = mpimg.imread(image_path)

    plt.subplot(2, 2, idx + 1)
    plt.imshow(img, cmap='gray')  # MRIs are grayscale
    plt.title(class_name, fontsize=14)
    plt.axis('off')

plt.suptitle('Sample MRI Images from Each Class', fontsize=20)
plt.tight_layout()
plt.show()

# Collect image sizes
widths = []
heights = []

for class_name in class_names:
    class_folder = os.path.join(train_path, class_name)
    images = os.listdir(class_folder)

    for img_name in images:
        img_path = os.path.join(class_folder, img_name)
        try:
            img = Image.open(img_path)
            widths.append(img.size[0])
            heights.append(img.size[1])
        except:
            continue  # Skip unreadable images

# Plotting Width Distribution
plt.figure(figsize=(14,6))
sns.histplot(widths, color='blue', kde=True)
plt.title('Distribution of Image Widths', fontsize=16)
plt.xlabel('Width (pixels)')
plt.ylabel('Frequency')
plt.show()

# Plotting Height Distribution
plt.figure(figsize=(14,6))
sns.histplot(heights, color='green', kde=True)
plt.title('Distribution of Image Heights', fontsize=16)
plt.xlabel('Height (pixels)')
plt.ylabel('Frequency')
plt.show()

"""# Image Size Distribution Analysis
The majority of brain tumor images have widths and heights clustered around 500 pixels.
However, a few images are significantly smaller or larger, which could affect model performance if not standardized.

‚û°Ô∏è To ensure uniformity and prevent bias toward larger/smaller images, **resizing** all images to a standard dimension (e.g., 224x224) during preprocessing is highly recommended.

This step will help the neural network focus on the medical patterns rather than irrelevant size differences.

"""

# Pixel Intensity Distribution
import cv2

all_pixels = []

for class_name in class_names:
    class_folder = os.path.join(train_path, class_name)
    images = os.listdir(class_folder)

    for img_name in images[:100]:  # Sample 100 images per class to save time
        img_path = os.path.join(class_folder, img_name)
        try:
            img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)
            if img is not None:
                pixels = img.flatten()
                all_pixels.extend(pixels)
        except:
            continue

# Plotting the pixel intensity distribution
plt.figure(figsize=(10,6))
sns.histplot(all_pixels, bins=50, color='purple', kde=True)
plt.title('Pixel Intensity Distribution (Grayscale)', fontsize=16)
plt.xlabel('Pixel Intensity (0-255)')
plt.ylabel('Frequency')
plt.show()

"""### Pixel Intensity Analysis
The majority of pixel values are concentrated at low intensities (0‚Äì50), confirming the dominance of dark backgrounds typical of MRI scans.
A secondary peak between 50 and 100 represents the brain structures and tumors.
Very few pixels reach maximum intensity (255), indicating minimal saturation.

‚û°Ô∏è To improve learning stability, it is recommended to **normalize pixel values** (rescale 0‚Äì255 to 0‚Äì1) during model training.

"""

import matplotlib.pyplot as plt
import numpy as np
import os
from PIL import Image
import random

# Paths to training and testing datasets
train_path = '/content/drive/MyDrive/BRAIN_TUMOR/Training/'
test_path = '/content/drive/MyDrive/BRAIN_TUMOR/Testing/'

# Get a list of class directories in the training set (assumes one directory per class)
train_classes = os.listdir(train_path)

# Function to load a sample image from a class directory
def load_image(class_name, dataset_path):
    class_path = os.path.join(dataset_path, class_name)
    image_files = os.listdir(class_path)
    random_image_file = random.choice(image_files)  # Select a random image
    image_path = os.path.join(class_path, random_image_file)

    # Open and return the image
    image = Image.open(image_path)
    return image, random_image_file

# Create a montage of images, one from each class
def create_image_montage(classes, dataset_path, n_images_per_class=3):
    fig, axes = plt.subplots(len(classes), n_images_per_class, figsize=(15, 5))

    for i, class_name in enumerate(classes):
        for j in range(n_images_per_class):
            image, image_name = load_image(class_name, dataset_path)
            axes[i, j].imshow(image)
            axes[i, j].axis('off')  # Hide axes

            # Overlay the class label and image details
            axes[i, j].set_title(f"Class: {class_name}\nImage: {image_name}")

    plt.tight_layout()
    plt.show()

# Show class-wise image montage for training dataset
print("Training Data Montage:")
create_image_montage(train_classes, train_path)

# Show class-wise image montage for testing dataset (optional)
print("Testing Data Montage:")
create_image_montage(train_classes, test_path)

import matplotlib.pyplot as plt
import os
import random
from PIL import Image

# Set number of images to display per class
num_samples_per_class = 6

# Class names
class_names = sorted(os.listdir(train_path))

plt.figure(figsize=(20, 12))

# Loop through each class
for idx, class_name in enumerate(class_names):
    class_folder = os.path.join(train_path, class_name)
    image_files = os.listdir(class_folder)

    # Select random images
    selected_images = random.sample(image_files, num_samples_per_class)

    for j, img_name in enumerate(selected_images):
        img_path = os.path.join(class_folder, img_name)
        img = Image.open(img_path)

        plt.subplot(len(class_names), num_samples_per_class, idx * num_samples_per_class + j + 1)
        plt.imshow(img, cmap='gray')
        plt.title(class_name, fontsize=8)
        plt.axis('off')

plt.suptitle('Sample Images from Each Class', fontsize=20)
plt.tight_layout()
plt.show()

import matplotlib.pyplot as plt
import os
import random
from PIL import Image

# Set number of images to display per class
num_samples_per_class = 6

# Class names
class_names = sorted(os.listdir(train_path))

plt.figure(figsize=(20, 12))

for idx, class_name in enumerate(class_names):
    class_folder = os.path.join(train_path, class_name)
    image_files = os.listdir(class_folder)
    selected_images = random.sample(image_files, num_samples_per_class)

    for j, img_name in enumerate(selected_images):
        img_path = os.path.join(class_folder, img_name)
        img = Image.open(img_path)

        plt.subplot(len(class_names), num_samples_per_class, idx * num_samples_per_class + j + 1)
        plt.imshow(img, cmap='gray')
        plt.title(class_name, fontsize=8)
        plt.axis('off')

plt.suptitle('Sample Images from Each Class', fontsize=20)
plt.tight_layout()
plt.show()

import seaborn as sns
import pandas as pd
import os

# Assuming train_path is defined and points to your training data directory
train_path = '/content/drive/MyDrive/BRAIN_TUMOR/Training/'  # Update if necessary

# Create a dictionary to store the counts
train_counts = {}
for class_name in os.listdir(train_path):
    class_folder = os.path.join(train_path, class_name)
    if os.path.isdir(class_folder):  # Check if it's a directory
        train_counts[class_name] = len(os.listdir(class_folder))

# Create the DataFrame
train_df = pd.DataFrame(list(train_counts.items()), columns=['Class', 'Number of Images'])

# Count of images per class
train_class_counts = train_df['Class'].value_counts()

# Plot Pie Chart
plt.figure(figsize=(10, 8))
colors = sns.color_palette('pastel')[0:5]

plt.pie(train_class_counts, labels=train_class_counts.index, colors=colors,
        autopct='%.1f%%', startangle=90, textprops={'fontsize': 14})

plt.title('Training Dataset Class Distribution', fontsize=18, fontweight='bold')
plt.show()

# === Essential Imports ===
import os
import numpy as np
import pandas as pd

# === Visualization Imports ===
import matplotlib.pyplot as plt
import seaborn as sns

# === Image Processing ===
from PIL import Image
import cv2

# === Deep Learning (later steps) ===
import tensorflow as tf
from tensorflow.keras.preprocessing.image import ImageDataGenerator

# === Settings ===
sns.set_style('whitegrid')  # clean seaborn style
plt.rcParams['figure.figsize'] = (8,6)  # default figure size

import numpy as np
import cv2
import pandas as pd
import os
import matplotlib.pyplot as plt
import seaborn as sns


# Function to calculate average brightness
def calculate_brightness(image_path):
    img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)
    return np.mean(img)

# Calculate brightness for 100 random images
brightness_list = []
classes_list = []

for class_name in class_names:
    class_folder = os.path.join(train_path, class_name)
    image_files = os.listdir(class_folder)
    sampled_images = np.random.choice(image_files, size=25, replace=False)  # 25 images per class

    for img_file in sampled_images:
        img_path = os.path.join(class_folder, img_file)
        brightness = calculate_brightness(img_path)
        brightness_list.append(brightness)
        classes_list.append(class_name)

# Create dataframe
brightness_df = pd.DataFrame({'Class': classes_list, 'Brightness': brightness_list})

# Plot brightness distribution
plt.figure(figsize=(10,6))
sns.boxplot(x='Class', y='Brightness', data=brightness_df, palette='Set2')
plt.title('Image Brightness Distribution by Class', fontsize=18)
plt.ylabel('Average Brightness (0-255)')
plt.xlabel('Tumor Class')
plt.show()

from tensorflow.keras.applications import VGG16
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Flatten, Dropout
from tensorflow.keras.optimizers import Adam

# Load pre-trained VGG16 without top layers
base_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))

# Freeze base model layers
for layer in base_model.layers:
    layer.trainable = False

# Build new model on top
model = Sequential([
    base_model,
    Flatten(),
    Dense(256, activation='relu'),
    Dropout(0.5),
    Dense(4, activation='softmax')  # 4 classes
])

# Compile the model
model.compile(optimizer=Adam(learning_rate=0.0001),
              loss='categorical_crossentropy',
              metrics=['accuracy'])

model.summary()

from tensorflow.keras.applications import VGG16
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Flatten, Dropout
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau
from tensorflow.keras.models import load_model

# 1. Load VGG16 base model
base_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))

# Freeze all layers initially
for layer in base_model.layers:
    layer.trainable = False

# 2. Build the model
model = Sequential([
    base_model,
    Flatten(),
    Dense(256, activation='relu'),
    Dropout(0.5),
    Dense(4, activation='softmax')  # 4 classes
])

# 3. Compile the model
model.compile(optimizer=Adam(learning_rate=0.0001),
              loss='categorical_crossentropy',
              metrics=['accuracy'])

model.summary()

# 4. Your Data Paths
train_path = '/content/drive/MyDrive/BRAIN_TUMOR/Training/'
test_path = '/content/drive/MyDrive/BRAIN_TUMOR/Testing/'

# 5. Data Generators
train_datagen = ImageDataGenerator(
    rescale=1./255,
    rotation_range=40,
    width_shift_range=0.3,
    height_shift_range=0.3,
    shear_range=0.3,
    zoom_range=0.3,
    horizontal_flip=True,
    brightness_range=[0.7, 1.3],
    fill_mode='nearest')

val_datagen = ImageDataGenerator(rescale=1./255)

train_generator = train_datagen.flow_from_directory(
    train_path,
    target_size=(224, 224),
    batch_size=32,
    class_mode='categorical')

validation_generator = val_datagen.flow_from_directory(
    test_path,
    target_size=(224, 224),
    batch_size=32,
    class_mode='categorical')

# 6. Callbacks
checkpoint_path = '/content/drive/MyDrive/best_model.keras'  # Save directly to Drive!

early_stopping = EarlyStopping(monitor='val_loss', patience=7, restore_best_weights=True)
checkpoint = ModelCheckpoint(checkpoint_path, save_best_only=True, monitor='val_loss')
lr_scheduler = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, verbose=1, min_lr=1e-7)

# 7. First Training Phase
history = model.fit(
    train_generator,
    epochs=15,
    validation_data=validation_generator,
    callbacks=[early_stopping, checkpoint, lr_scheduler])

# 8. Fine-Tune VGG16 (Unfreeze last 8 layers)
for layer in base_model.layers[-8:]:
    layer.trainable = True

# Recompile with lower learning rate for fine-tuning
model.compile(optimizer=Adam(learning_rate=1e-5),
              loss='categorical_crossentropy',
              metrics=['accuracy'])

# 9. Fine-Tuning Phase
history_finetune = model.fit(
    train_generator,
    epochs=33,
    validation_data=validation_generator,
    callbacks=[early_stopping, checkpoint, lr_scheduler])

# 10. Load Best Model (after training finishes)
best_model = load_model(checkpoint_path)

# 11. Save Final Model Permanently (Different Name)
final_model_path = '/content/drive/MyDrive/brain_tumor_final_model.keras'
best_model.save(final_model_path)

print(f"‚úÖ Model successfully saved to: {final_model_path}")

from tensorflow.keras.models import load_model

# Load the final saved model
model = load_model('/content/drive/MyDrive/brain_tumor_final_model.keras')

# Evaluate on test set
loss, accuracy = model.evaluate(validation_generator)
print(f"‚úÖ Test Accuracy: {accuracy * 100:.2f}%")

import matplotlib.pyplot as plt

# Combine histories if you used fine-tuning
def combine_history(h1, h2):
    history = {}
    for key in h1.history.keys():
        history[key] = h1.history[key] + h2.history[key]
    return history

combined_history = combine_history(history, history_finetune)

# Plot
plt.figure(figsize=(12, 5))

# Accuracy
plt.subplot(1, 2, 1)
plt.plot(combined_history['accuracy'], label='Train Accuracy')
plt.plot(combined_history['val_accuracy'], label='Val Accuracy')
plt.title('Model Accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.legend()

# Loss
plt.subplot(1, 2, 2)
plt.plot(combined_history['loss'], label='Train Loss')
plt.plot(combined_history['val_loss'], label='Val Loss')
plt.title('Model Loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.legend()

plt.tight_layout()
plt.show()

import numpy as np
from sklearn.metrics import classification_report, confusion_matrix
import seaborn as sns
import matplotlib.pyplot as plt

# STEP 1: Get true labels and predictions
Y_true = []
Y_pred = []

# Reset the generator before predicting
validation_generator.reset()

# Predict batch-wise
predictions = model.predict(validation_generator, verbose=1)

# Convert predictions and labels to class indices
Y_pred = np.argmax(predictions, axis=1)
Y_true = validation_generator.classes

# STEP 2: Get class labels
class_labels = list(validation_generator.class_indices.keys())

# STEP 3: Confusion Matrix
cm = confusion_matrix(Y_true, Y_pred)

plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
            xticklabels=class_labels, yticklabels=class_labels)
plt.title('Confusion Matrix')
plt.xlabel('Predicted Label')
plt.ylabel('True Label')
plt.show()

# STEP 4: Classification Report
report = classification_report(Y_true, Y_pred, target_names=class_labels)
print("Classification Report:\n")
print(report)

from sklearn.metrics import classification_report
print(classification_report(Y_true, Y_pred, target_names=class_labels)) # Changed y_true to Y_true, y_pred to Y_pred, and class_names to class_labels

import tensorflow as tf
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.applications import VGG16
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Dense, Dropout, GlobalAveragePooling2D
from tensorflow.keras.callbacks import ReduceLROnPlateau
from sklearn.metrics import classification_report, confusion_matrix
import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np

# Paths
train_path = '/content/drive/MyDrive/BRAIN_TUMOR/Training/'
test_path = '/content/drive/MyDrive/BRAIN_TUMOR/Testing/'

# Image and batch size
img_size = (224, 224)
batch_size = 32

# Data generators
train_datagen = ImageDataGenerator(rescale=1./255, rotation_range=15, zoom_range=0.1, horizontal_flip=True)
test_datagen = ImageDataGenerator(rescale=1./255)

train_generator = train_datagen.flow_from_directory(
    train_path, target_size=img_size, batch_size=batch_size, class_mode='categorical'
)

test_generator = test_datagen.flow_from_directory(
    test_path, target_size=img_size, batch_size=batch_size, class_mode='categorical', shuffle=False
)

# VGG16 base
base_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))
base_model.trainable = True
for layer in base_model.layers[:15]:
    layer.trainable = False

# Custom head
x = base_model.output
x = GlobalAveragePooling2D()(x)
x = Dense(512, activation='relu')(x)
x = Dropout(0.5)(x)
predictions = Dense(4, activation='softmax')(x)

model = Model(inputs=base_model.input, outputs=predictions)
model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])

# Learning rate scheduler
lr_scheduler = ReduceLROnPlateau(monitor='val_loss', patience=2, factor=0.5, verbose=1)

# Training
model.fit(
    train_generator,
    epochs=10,
    validation_data=test_generator,  # using test set for val as no val set provided
    callbacks=[lr_scheduler]
)

# Prediction
Y_pred = model.predict(test_generator)
y_pred = np.argmax(Y_pred, axis=1)
y_true = test_generator.classes
class_labels = list(test_generator.class_indices.keys())

# Classification report
print("\nClassification Report:\n")
print(classification_report(y_true, y_pred, target_names=class_labels))

# Confusion matrix
cm = confusion_matrix(y_true, y_pred)
plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_labels, yticklabels=class_labels)
plt.xlabel('Predicted')
plt.ylabel('True')
plt.title('Confusion Matrix')
plt.show()

model.save('/content/drive/MyDrive/brain_tumor_final_model_v2.keras')

from tensorflow.keras.models import load_model

model = load_model('/content/drive/MyDrive/brain_tumor_final_model_v2.keras')

!pip install tf-keras-vis
import matplotlib.pyplot as plt
from tf_keras_vis.gradcam import Gradcam
from tf_keras_vis.utils.model_modifiers import ReplaceToLinear
from tf_keras_vis.utils.scores import CategoricalScore
import tensorflow as tf
import numpy as np

# Preprocess an image
img_path = '/content/drive/MyDrive/BRAIN_TUMOR/Testing/glioma/Te-glTr_0001.jpg'  # change this path
img = tf.keras.preprocessing.image.load_img(img_path, target_size=(224, 224))
img_array = tf.keras.preprocessing.image.img_to_array(img) / 255.0
img_array = np.expand_dims(img_array, axis=0)

# Set up GradCAM
score = CategoricalScore([np.argmax(model.predict(img_array))])
gradcam = Gradcam(model,
                  model_modifier=ReplaceToLinear(),
                  clone=True)

cam = gradcam(score,
              img_array,
              penultimate_layer='block5_conv3')  # Use last conv layer of VGG16
heatmap = np.uint8(255 * cam[0])

# Visualize
plt.imshow(img)
plt.imshow(heatmap, cmap='jet', alpha=0.5)  # Overlay heatmap
plt.title("Grad-CAM Output")
plt.axis('off')
plt.show()

!pip install shap

!pip install lime

from lime import lime_image
from skimage.segmentation import mark_boundaries

explainer = lime_image.LimeImageExplainer()
explanation = explainer.explain_instance(
    image=np.squeeze(img_array),
    classifier_fn=model.predict,
    top_labels=4,
    hide_color=0,
    num_samples=1000
)

# Visualize for top predicted label
from matplotlib import pyplot as plt
temp, mask = explanation.get_image_and_mask(
    explanation.top_labels[0],
    positive_only=True,
    num_features=5,
    hide_rest=False
)
plt.imshow(mark_boundaries(temp / 255.0, mask))
plt.title("LIME Explanation")
plt.axis('off')
plt.show()

lime_output_path = "/content/drive/MyDrive/lime_explanation.png"
plt.imsave(lime_output_path, mark_boundaries(temp / 255.0, mask))

import numpy as np
from tensorflow.keras.models import load_model
from tensorflow.keras.preprocessing import image
import matplotlib.pyplot as plt

# 1. Load your trained model
model = load_model('/content/drive/MyDrive/brain_tumor_final_model_v2.keras')

# 2. Define your class labels (in the same order used during training)
class_names = ['glioma', 'meningioma', 'notumor', 'pituitary']

# 3. Load and preprocess the image
img_path = '/content/drive/MyDrive/BRAIN_TUMOR/Testing/glioma/Te-glTr_0001.jpg'  # Update with a valid image path from your dataset
img = image.load_img(img_path, target_size=(224, 224))  # size must match model input
img_array = image.img_to_array(img)
img_array = np.expand_dims(img_array, axis=0)  # (1, 224, 224, 3)
img_array = img_array / 255.0  # normalize if you trained on normalized images

# 4. Predict
predictions = model.predict(img_array)
predicted_class = class_names[np.argmax(predictions)]

# 5. Display result
print("Predicted Class:", predicted_class)
print("Confidence Scores:", predictions[0])

# Optional: Visualize
plt.imshow(img)
plt.title(f"Prediction: {predicted_class}")
plt.axis('off')
plt.show()

